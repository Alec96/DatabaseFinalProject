---
title: "CS3200 Final Proj - Duncan Muir"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(XML)
library(xml2)
library(rvest)
```

# CSS Selector Functions
```{r}
scrapeName <- function(x) {
  options(timeout= 4000000)
  climbName <- str_trim(html_text(html_node(read_html(x), 'h1')))
  return(climbName)
}

scrapeGrade <- function(x) {
  options(timeout= 4000000)
  climbGrade <-  
    html_text(html_node(read_html(x), '.mr-2'))
  return(climbGrade)
} 

scrapeDesc <- function (x) {
  options(timeout= 4000000)
  climbDesc <- html_text(html_node(read_html(x), '.max-height-xs-600:nth-child(1) .fr-view'))
  return(climbDesc)
}

scrapeBeta <- function (x) {
  options(timeout= 4000000)
  climbBeta <- html_text(html_node(read_html(x), '.max-height-xs-600:nth-child(2) .fr-view'))
  return(climbBeta)
}

scrapePro <- function (x) {
  options(timeout= 4000000)
  climbPro <- html_text(html_node(read_html(x), '.max-height-xs-600~ .max-height-xs-600+ .max-height-xs-600 .fr-view'))
  return(climbPro)
}

scrapeFA <- function(x) {
  options(timeout= 4000000)
  climbFA <- html_text(html_node(read_html(x), '.description-details tr:nth-child(2) td+ td'))
  climbFA <- gsub("\n","",climbFA)
  climbFA <- str_trim(climbFA)
  return(climbFA)
}

scrapeTicks <- function(x) {
  options(timeout= 4000000)
  climbTicks <- html_text(html_node(read_html(x), '.col-sm-8 .text-muted'))
  return(climbTicks)
}

scrapeRating <- function(x) {
  options(timeout= 4000000)
  climbRating <- str_trim(gsub("\n", "", html_text(html_node(read_html(x), '#route-star-avg span')))) 
  return(climbRating)
}

```

```{r}
RTL_STAT <- "https://www.mountainproject.com/route/stats/105945043/ride-the-lightning"
IJ <- "https://www.mountainproject.com/route/stats/113491812/indiana-jones"


html_text(html_nodes(read_html(RTL), ".mb-half.text-warm a"))

getSuggGradeTable<- function(x) {
  tables <- html_table(html_nodes(read_html(x), "table"))
  df <- bind_rows(tables)
  df <- filter(df, !is.na(X2))
  suggested_grades <- df[!grepl("\\,",df$X2),]
  return(suggested_grades)
}

getCommentTable<- function(x) {
  tables <- html_table(html_nodes(read_html(x), "table"))
  df <- bind_rows(tables)
  df <- filter(df, !is.na(X2))
  tick_comments <- df[grepl("\\,",df$X2),]
  return(tick_comments)
}

```



```{r}
scrapeLinks <- function(url){
  options(timeout= 4000000)
  # Create an html document from the url
  webpage <- xml2::read_html(url)
  # Extract the URLs
  url_ <- webpage %>%
    html_nodes("a") %>%
    html_attr("href")
  # Extract the link text
  link_ <- webpage %>%
    html_nodes("a") %>%
    html_text()
  return(data_frame(link = link_, url = url_))
}

getClimbData <- function(x,y) {
  options(timeout= 4000000)
  x <- as.character(x)
  y <- as.character(y)
  names <- sapply(x, scrapeName)
  grades <- sapply(x, scrapeGrade)
  fas <- sapply(x, scrapeFA)
  descs <- sapply(x, scrapeDesc)
  beta <- sapply(x, scrapeBeta)
  pro <- sapply(x, scrapePro)
  ticks <- sapply(y, scrapeTicks)
  ratings <- sapply(y, scrapeRating)
  df <- data.frame("names" = names, 
                   "grades" = grades, 
                   "FA" = fas, 
                   "descriptions" = descs,
                   "beta" = beta,
                   "protection" = pro, 
                   "ticks" = ticks, 
                   "ratings" = ratings, 
                   row.names = NULL)
  return(df)
}

getAllComments <- function(stats, climb_names) {
  options(timeout= 4000000)
  stats <- as.character(stats)
  listOfTables <- lapply(stats, getCommentTable)
  try(
    for (i in 1:length(listOfTables)) {
      listOfTables[[i]]$climb_name <- climb_names[i]
    }, silent = TRUE)
  out <- bind_rows(listOfTables)
  return(out)
}

getAllSuggestedGrades <- function(stats, climb_names) {
  options(timeout = 4000000)
  stats <- as.character(stats)
  listOfTables <- lapply(stats, getSuggGradeTable)
  try(
    for (i in 1:length(listOfTables)) {
      listOfTables[[i]]$climb_name <- climb_names[i]
    }, silent = TRUE)
  out <- bind_rows(listOfTables)
  return(out)
}
```


Gets Route Links and Stats Links for Given query
```{r}
mp_scraper <- function(x) {
  options(timeout= 4000000)
  all_links <- scrapeLinks(x)
  route_links <- filter(all_links, grepl("/route/", url))
  route_urls <- as.character(unique(route_links$url))
  stat_urls <- as.character(gsub("/route/", "/route/stats/", route_urls))
  climb_df <- getClimbData(route_urls, stat_urls)
  comment_df <- getAllComments(stat_urls, climb_df$name)
  sugg_grade_df <- getAllSuggestedGrades(stat_urls, climb_df$name)
  all_tables <- list(climb_df,comment_df, sugg_grade_df)
  return(all_tables)
}
test <- mp_scraper(storm_boulder_url)

test_climb <- test[[1]]
test_comment <- test[[2]]
test_sugg_grade <- test [[3]]
```




# Urls
```{r}
storm_boulder_url <- "https://www.mountainproject.com/route-finder?selectedIds=106523385&type=boulder&diffMinrock=1800&diffMinboulder=20000&diffMinaid=70000&diffMinice=30000&diffMinmixed=50000&diffMaxrock=5500&diffMaxboulder=21400&diffMaxaid=75260&diffMaxice=36500&diffMaxmixed=60000&is_trad_climb=1&is_sport_climb=1&is_top_rope=1&stars=0&pitches=0&sort1=popularity+desc&sort2=rating"

RTL <- "https://www.mountainproject.com/route/105945043/ride-the-lightning"  
```

# Runs Scraper
```{r}
#storm_boulders_data <- mp_scraper(storm_boulder_url)
setwd("/Users/duncanmuir/Documents/Classwork/S19/CS3200/FinalProj")
write.csv(test_climb, file = "storm_boulders_data_raw_climbs.csv")
write.csv(test_comment, file = "storm_boulders_data_raw_comments.csv")
write.csv(test_sugg_grade, file = "storm_boulders_data_raw_sugg_grades.csv")

```


# Cleaning
```{r}

sb_clean <- read.csv("storm_boulders_data_raw.csv")
sb_clean <- select(sb_clean, -X)
sb_splitratings <- str_split(sb_clean$ratings, " ")
sb_clean$avg.rating <- as.numeric(unlist(lapply(sb_splitratings, `[`, 2)))
sb_clean$votes <- as.numeric(unlist(lapply(sb_splitratings, `[`, 4)))
sb_clean <- select(sb_clean, -ratings)

sb_clean$grades <- gsub("V", "", sb_clean$grades)
sb_clean$grades <- as.character(unlist(lapply(str_split(sb_clean$grades, "\\+|\\-|/| "), `[`,1)))



sb_clean$ticks[is.na(sb_clean$ticks)] <- 0
```

